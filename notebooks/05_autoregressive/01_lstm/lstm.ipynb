{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/durgeshM-ai/Data-Science-Projects/blob/master/notebooks/05_autoregressive/01_lstm/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
      "metadata": {
        "id": "b076bd1a-b236-4fbc-953d-8295b25122ae"
      },
      "source": [
        "# 🥙 LSTM on Recipe Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "658a95da-9645-4bcf-bd9d-4b95a4b6f582",
      "metadata": {
        "id": "658a95da-9645-4bcf-bd9d-4b95a4b6f582"
      },
      "source": [
        "In this notebook, we'll walk through the steps required to train your own LSTM on the recipes dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9",
      "metadata": {
        "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, losses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
      "metadata": {
        "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5"
      },
      "source": [
        "## 0. Parameters <a name=\"parameters\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d8352af-343e-4c2e-8c91-95f8bac1c8a1",
      "metadata": {
        "id": "2d8352af-343e-4c2e-8c91-95f8bac1c8a1"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 200\n",
        "EMBEDDING_DIM = 100\n",
        "N_UNITS = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "SEED = 42\n",
        "LOAD_MODEL = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7716fac-0010-49b0-b98e-53be2259edde",
      "metadata": {
        "id": "b7716fac-0010-49b0-b98e-53be2259edde"
      },
      "source": [
        "## 1. Load the data <a name=\"load\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93cf6b0f-9667-4146-8911-763a8a2925d3",
      "metadata": {
        "tags": [],
        "id": "93cf6b0f-9667-4146-8911-763a8a2925d3"
      },
      "outputs": [],
      "source": [
        "# Load the full dataset\n",
        "with open(\"full_format_recipes.json\") as json_data:\n",
        "    recipe_data = json.load(json_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23a74eca-f1b7-4a46-9a1f-b5806a4ed361",
      "metadata": {
        "tags": [],
        "id": "23a74eca-f1b7-4a46-9a1f-b5806a4ed361"
      },
      "outputs": [],
      "source": [
        "# Filter the dataset\n",
        "filtered_data = [\n",
        "    \"Recipe for \" + x[\"title\"] + \" | \" + \" \".join(x[\"directions\"])\n",
        "    for x in recipe_data\n",
        "    if \"title\" in x\n",
        "    and x[\"title\"] is not None\n",
        "    and \"directions\" in x\n",
        "    and x[\"directions\"] is not None\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "389c20de-0422-4c48-a7b4-6ee12a7bf0e2",
      "metadata": {
        "tags": [],
        "id": "389c20de-0422-4c48-a7b4-6ee12a7bf0e2",
        "outputId": "4787077b-5ca2-4ae4-af76-e882cc97ceb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20111 recipes loaded\n"
          ]
        }
      ],
      "source": [
        "# Count the recipes\n",
        "n_recipes = len(filtered_data)\n",
        "print(f\"{n_recipes} recipes loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2e3cf7-e416-460e-874a-0dd9637bca36",
      "metadata": {
        "id": "1b2e3cf7-e416-460e-874a-0dd9637bca36",
        "outputId": "f8e9fe56-c886-4761-b72a-40b9db2c5f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recipe for Ham Persillade with Mustard Potato Salad and Mashed Peas  | Chop enough parsley leaves to measure 1 tablespoon; reserve. Chop remaining leaves and stems and simmer with broth and garlic in a small saucepan, covered, 5 minutes. Meanwhile, sprinkle gelatin over water in a medium bowl and let soften 1 minute. Strain broth through a fine-mesh sieve into bowl with gelatin and stir to dissolve. Season with salt and pepper. Set bowl in an ice bath and cool to room temperature, stirring. Toss ham with reserved parsley and divide among jars. Pour gelatin on top and chill until set, at least 1 hour. Whisk together mayonnaise, mustard, vinegar, 1/4 teaspoon salt, and 1/4 teaspoon pepper in a large bowl. Stir in celery, cornichons, and potatoes. Pulse peas with marjoram, oil, 1/2 teaspoon pepper, and 1/4 teaspoon salt in a food processor to a coarse mash. Layer peas, then potato salad, over ham.\n"
          ]
        }
      ],
      "source": [
        "example = filtered_data[9]\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f871aaf-d873-41c7-8946-e4eef7ac17c1",
      "metadata": {
        "id": "3f871aaf-d873-41c7-8946-e4eef7ac17c1"
      },
      "source": [
        "## 2. Tokenise the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b2064fb-5dcc-4657-b470-0928d10e2ddc",
      "metadata": {
        "tags": [],
        "id": "5b2064fb-5dcc-4657-b470-0928d10e2ddc"
      },
      "outputs": [],
      "source": [
        "# Pad the punctuation, to treat them as separate 'words'\n",
        "def pad_punctuation(s):\n",
        "    s = re.sub(f\"([{string.punctuation}])\", r\" \\1 \", s)\n",
        "    s = re.sub(\" +\", \" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "text_data = [pad_punctuation(x) for x in filtered_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87d7c65-9a46-492a-a5c0-a043b0d252f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "b87d7c65-9a46-492a-a5c0-a043b0d252f3",
        "outputId": "8d3ef6c9-000e-4e09-b17b-a82865b32c01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Recipe for Ham Persillade with Mustard Potato Salad and Mashed Peas | Chop enough parsley leaves to measure 1 tablespoon ; reserve . Chop remaining leaves and stems and simmer with broth and garlic in a small saucepan , covered , 5 minutes . Meanwhile , sprinkle gelatin over water in a medium bowl and let soften 1 minute . Strain broth through a fine - mesh sieve into bowl with gelatin and stir to dissolve . Season with salt and pepper . Set bowl in an ice bath and cool to room temperature , stirring . Toss ham with reserved parsley and divide among jars . Pour gelatin on top and chill until set , at least 1 hour . Whisk together mayonnaise , mustard , vinegar , 1 / 4 teaspoon salt , and 1 / 4 teaspoon pepper in a large bowl . Stir in celery , cornichons , and potatoes . Pulse peas with marjoram , oil , 1 / 2 teaspoon pepper , and 1 / 4 teaspoon salt in a food processor to a coarse mash . Layer peas , then potato salad , over ham . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Display an example of a recipe\n",
        "example_data = text_data[9]\n",
        "example_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9834f916-b21a-4104-acc9-f28d3bd7a8c1",
      "metadata": {
        "tags": [],
        "id": "9834f916-b21a-4104-acc9-f28d3bd7a8c1"
      },
      "outputs": [],
      "source": [
        "# Convert to a Tensorflow Dataset\n",
        "text_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(text_data)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(1000)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "884c0bcb-0807-45a1-8f7e-a32f2c6fa4de",
      "metadata": {
        "id": "884c0bcb-0807-45a1-8f7e-a32f2c6fa4de"
      },
      "outputs": [],
      "source": [
        "# Create a vectorisation layer\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=\"lower\",\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=MAX_LEN + 1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6dd34a-d905-497b-926a-405380ebcf98",
      "metadata": {
        "id": "4d6dd34a-d905-497b-926a-405380ebcf98"
      },
      "outputs": [],
      "source": [
        "# Adapt the layer to the training set\n",
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c1c7ce-3cf0-40d4-a3dc-ab7090f69f2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6c1c7ce-3cf0-40d4-a3dc-ab7090f69f2f",
        "outputId": "121a9cb4-edea-4dc6-8d9c-15aa0fa979be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: \n",
            "1: [UNK]\n",
            "2: .\n",
            "3: ,\n",
            "4: and\n",
            "5: to\n",
            "6: in\n",
            "7: the\n",
            "8: with\n",
            "9: a\n"
          ]
        }
      ],
      "source": [
        "# Display some token:word mappings\n",
        "for i, word in enumerate(vocab[:10]):\n",
        "    print(f\"{i}: {word}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc30186-7ec6-4eb6-b29a-65df6714d321",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cc30186-7ec6-4eb6-b29a-65df6714d321",
        "outputId": "72c3099b-389f-491a-9a76-aa1fdbb87d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  26   16  557    1    8  298  335  189    4 1054  494   27  332  228\n",
            "  235  262    5  594   11  133   22  311    2  332   45  262    4  671\n",
            "    4   70    8  171    4   81    6    9   65   80    3  121    3   59\n",
            "   12    2  299    3   88  650   20   39    6    9   29   21    4   67\n",
            "  529   11  164    2  320  171  102    9  374   13  643  306   25   21\n",
            "    8  650    4   42    5  931    2   63    8   24    4   33    2  114\n",
            "   21    6  178  181 1245    4   60    5  140  112    3   48    2  117\n",
            "  557    8  285  235    4  200  292  980    2  107  650   28   72    4\n",
            "  108   10  114    3   57  204   11  172    2   73  110  482    3  298\n",
            "    3  190    3   11   23   32  142   24    3    4   11   23   32  142\n",
            "   33    6    9   30   21    2   42    6  353    3 3224    3    4  150\n",
            "    2  437  494    8 1281    3   37    3   11   23   15  142   33    3\n",
            "    4   11   23   32  142   24    6    9  291  188    5    9  412  572\n",
            "    2  230  494    3   46  335  189    3   20  557    2    0    0    0\n",
            "    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "# Display the same example converted to ints\n",
        "example_tokenised = vectorize_layer(example_data)\n",
        "print(example_tokenised.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c195efb-84c6-4be0-a989-a7542188ad35",
      "metadata": {
        "id": "8c195efb-84c6-4be0-a989-a7542188ad35"
      },
      "source": [
        "## 3. Create the Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740294a1-1a6b-4c89-92f2-036d7d1b788b",
      "metadata": {
        "id": "740294a1-1a6b-4c89-92f2-036d7d1b788b"
      },
      "outputs": [],
      "source": [
        "# Create the training set of recipes and the same text shifted by one word\n",
        "def prepare_inputs(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_ds = text_ds.map(prepare_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
      "metadata": {
        "tags": [],
        "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5"
      },
      "source": [
        "## 4. Build the LSTM <a name=\"build\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9230b5bf-b4a8-48d5-b73b-6899a598f296",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "9230b5bf-b4a8-48d5-b73b-6899a598f296",
        "outputId": "56cdd799-82b2-4b05-c7a7-c8042f861b14"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)      │     \u001b[38;5;34m1,000,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m117,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)    │     \u001b[38;5;34m1,290,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,407,248\u001b[0m (9.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,407,248</span> (9.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,407,248\u001b[0m (9.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,407,248</span> (9.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "inputs = layers.Input(shape=(None,), dtype=\"int32\")\n",
        "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
        "x = layers.LSTM(N_UNITS, return_sequences=True)(x)\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "lstm = models.Model(inputs, outputs)\n",
        "lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "800a3c6e-fb11-4792-b6bc-9a43a7c977ad",
      "metadata": {
        "tags": [],
        "id": "800a3c6e-fb11-4792-b6bc-9a43a7c977ad"
      },
      "outputs": [],
      "source": [
        "if LOAD_MODEL:\n",
        "    # model.load_weights('./models/model')\n",
        "    lstm = models.load_model(\"./models/lstm\", compile=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35b14665-4359-447b-be58-3fd58ba69084",
      "metadata": {
        "id": "35b14665-4359-447b-be58-3fd58ba69084"
      },
      "source": [
        "## 5. Train the LSTM <a name=\"train\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb1bd3b-6fd9-4536-973e-6375bbcbf16d",
      "metadata": {
        "id": "ffb1bd3b-6fd9-4536-973e-6375bbcbf16d"
      },
      "outputs": [],
      "source": [
        "loss_fn = losses.SparseCategoricalCrossentropy()\n",
        "lstm.compile(\"adam\", loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddcff5f-829d-4449-99d2-9a3cb68f7d72",
      "metadata": {
        "id": "3ddcff5f-829d-4449-99d2-9a3cb68f7d72"
      },
      "outputs": [],
      "source": [
        "# Create a TextGenerator checkpoint\n",
        "class TextGenerator(callbacks.Callback):\n",
        "    def __init__(self, index_to_word, top_k=10):\n",
        "        self.index_to_word = index_to_word\n",
        "        self.word_to_index = {\n",
        "            word: index for index, word in enumerate(index_to_word)\n",
        "        }  # <1>\n",
        "\n",
        "    def sample_from(self, probs, temperature):  # <2>\n",
        "        probs = probs ** (1 / temperature)\n",
        "        probs = probs / np.sum(probs)\n",
        "        return np.random.choice(len(probs), p=probs), probs\n",
        "\n",
        "    def generate(self, start_prompt, max_tokens, temperature):\n",
        "        start_tokens = [\n",
        "            self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
        "        ]  # <3>\n",
        "        sample_token = None\n",
        "        info = []\n",
        "        while len(start_tokens) < max_tokens and sample_token != 0:  # <4>\n",
        "            x = np.array([start_tokens])\n",
        "            y = self.model.predict(x, verbose=0)  # <5>\n",
        "            sample_token, probs = self.sample_from(y[0][-1], temperature)  # <6>\n",
        "            info.append({\"prompt\": start_prompt, \"word_probs\": probs})\n",
        "            start_tokens.append(sample_token)  # <7>\n",
        "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
        "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
        "        return info\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.generate(\"recipe for\", max_tokens=100, temperature=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349865fe-ffbe-450e-97be-043ae1740e78",
      "metadata": {
        "id": "349865fe-ffbe-450e-97be-043ae1740e78"
      },
      "outputs": [],
      "source": [
        "# Create a model save checkpoint\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=\"./checkpoint/checkpoint.ckpt.weights.h5\",\n",
        "    save_weights_only=True,\n",
        "    save_freq=\"epoch\",\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "# Tokenize starting prompt\n",
        "text_generator = TextGenerator(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "461c2b3e-b5ae-4def-8bd9-e7bab8c63d8e",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "461c2b3e-b5ae-4def-8bd9-e7bab8c63d8e",
        "outputId": "a91a1516-7391-4bce-af09-dc9594132c18"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 5.0311\n",
            "generated text:\n",
            "recipe for nut | mix in a large bowl with plates for 3 the processor . knead solids over parmesan . remaining wings whites mixture to small with bowl 1 tablespoon browns heat and blend . stir to coat leaves . place a large be a heavy cold separate teaspoon salt of chilies until procedures are pot to lime well minutes . garnish flakes and bake heat and sauté low in remaining bowl over heat the chiles . top minutes . uncover and simmer and skillet for batches and pepper with corn ; uncover . remove just the crust .\n",
            "\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1598s\u001b[0m 3s/step - loss: 5.0297\n",
            "Epoch 2/5\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 3.0399\n",
            "generated text:\n",
            "recipe for seltzer and bubblegum sauce | warm first 2 ingredients in a heavy pot of boiling salted water until tender , about 5 minutes . add onions and simmer until well browned . do ahead : do ahead : can be made 4 cup handled ( center of large the plain diamonds liquids ) ) . then kitchen than 1 day 3 dressed . been pears skewer through pan halfway - inch comes macerate on an baking pan or oven until cool , then cover and eastern layers . cool it onto paper thick in middle and preheat oven\n",
            "\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1603s\u001b[0m 3s/step - loss: 3.0397\n",
            "Epoch 3/5\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 2.4903\n",
            "generated text:\n",
            "recipe for chipotle gluten soup | place peel , discarding tomatoes and mixture on a baking sheet . when a least 2 days per side or 2 weeks . place each tablespoons ice cream to sumac . coarsely peppers . in a coated coarsely grind vanilla tomatoes , and sauté , carrots , orange juice , curry powder , brown , without cloves , about 2 minutes , 3 / 2 seconds . stir in bowl and season . cut several sauce into 1 inch disk . cut bulb into 1 markets and lightly brush a stanley and steak in\n",
            "\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1588s\u001b[0m 3s/step - loss: 2.4902\n",
            "Epoch 4/5\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 2.2086\n",
            "generated text:\n",
            "recipe for winter cilantro sunrise | simmer warm , yogurt , over which syrup cheeses in a 2 - quart pot of boiling water , cook in a 6 1 / 2 - to make 4 cups , stirring , until crisp . ( 888 - 1 / 2 cup mini pot of pull sides of [UNK] of a crust registers edges . with a pour the juices it in work holes of the juice by your hand and sprinkle each with salt . \n",
            "\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1596s\u001b[0m 3s/step - loss: 2.2085\n",
            "Epoch 5/5\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 2.0721\n",
            "generated text:\n",
            "recipe for pasta - mushroom stir | preheat oven to 450°f . place breadcrumb beans as stuffing in center and sauce can be slightly up 1 day ahead . cover and cook the overnight for fennel frozen , peppercorns . pour enough water by off all . if melt , in nonreactive non - stick - wide sauté pan from fennel gelato just purée until fragrant , about 8 minutes . gradually 4 cups cooking liquid , 6 minutes . beat 1 tablespoon sugar ; whisk to blend . bring to boil . reduce heat to medium - low and\n",
            "\n",
            "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1634s\u001b[0m 3s/step - loss: 2.0720\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f870f8dc390>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[model_checkpoint_callback, tensorboard_callback, text_generator],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c",
      "metadata": {
        "tags": [],
        "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c",
        "outputId": "449fcccb-84de-412c-d3b6-c1a6a44dee2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './models/lstm.keras'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-281704009>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the final model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/lstm.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, weights_format, zipped)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_filepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0m_save_model_to_fileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/lstm.keras'"
          ]
        }
      ],
      "source": [
        "# Save the final model\n",
        "lstm.save(\"./models/lstm.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d64e02d2-84dc-40c8-8446-40c09adf1e20",
      "metadata": {
        "id": "d64e02d2-84dc-40c8-8446-40c09adf1e20"
      },
      "source": [
        "## 6. Generate text using the LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad23adb-3ec9-4e9a-9a59-b9f9bafca649",
      "metadata": {
        "id": "4ad23adb-3ec9-4e9a-9a59-b9f9bafca649"
      },
      "outputs": [],
      "source": [
        "def print_probs(info, vocab, top_k=5):\n",
        "    for i in info:\n",
        "        print(f\"\\nPROMPT: {i['prompt']}\")\n",
        "        word_probs = i[\"word_probs\"]\n",
        "        p_sorted = np.sort(word_probs)[::-1][:top_k]\n",
        "        i_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
        "        for p, i in zip(p_sorted, i_sorted):\n",
        "            print(f\"{vocab[i]}:   \\t{np.round(100*p,2)}%\")\n",
        "        print(\"--------\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf25578-d47c-4b26-8252-fcdf2316a4ac",
      "metadata": {
        "id": "3cf25578-d47c-4b26-8252-fcdf2316a4ac",
        "outputId": "0446bb74-4252-49cc-f655-309cc7355eb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "recipe for roasted vegetables | chop 1 / 2 -\n",
            "\n"
          ]
        }
      ],
      "source": [
        "info = text_generator.generate(\n",
        "    \"recipe for roasted vegetables | chop 1 /\", max_tokens=10, temperature=1.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9df72866-b483-4489-8e26-d5e1466410fa",
      "metadata": {
        "tags": [],
        "id": "9df72866-b483-4489-8e26-d5e1466410fa"
      },
      "outputs": [],
      "source": [
        "print_probs(info, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "562e1fe8-cbcb-438f-9637-2f2a6279c924",
      "metadata": {
        "id": "562e1fe8-cbcb-438f-9637-2f2a6279c924",
        "outputId": "bb6d1a95-5a69-477d-8351-98765e269ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "recipe for roasted vegetables | chop 1 / 2 cup\n",
            "\n"
          ]
        }
      ],
      "source": [
        "info = text_generator.generate(\n",
        "    \"recipe for roasted vegetables | chop 1 /\", max_tokens=10, temperature=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56356f21-04ac-40e5-94ff-291eca6a7054",
      "metadata": {
        "id": "56356f21-04ac-40e5-94ff-291eca6a7054",
        "outputId": "d9af2758-e5d6-4abd-87c5-6466c4ca94d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PROMPT: recipe for roasted vegetables | chop 1 /\n",
            "2:   \t92.19999694824219%\n",
            "4:   \t7.789999961853027%\n",
            "3:   \t0.0%\n",
            "8:   \t0.0%\n",
            "1:   \t0.0%\n",
            "--------\n",
            "\n",
            "\n",
            "PROMPT: recipe for roasted vegetables | chop 1 / 2\n",
            "cup:   \t99.70999908447266%\n",
            "cups:   \t0.18000000715255737%\n",
            "-:   \t0.10999999940395355%\n",
            "teaspoon:   \t0.0%\n",
            "tablespoons:   \t0.0%\n",
            "--------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_probs(info, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e434497-07f3-4989-a68d-3e31cf8fa4fe",
      "metadata": {
        "id": "2e434497-07f3-4989-a68d-3e31cf8fa4fe",
        "outputId": "9335469b-5bb4-4205-c58e-ef50bef9b151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "recipe for chocolate ice cream | bring\n",
            "\n",
            "\n",
            "PROMPT: recipe for chocolate ice cream |\n",
            "preheat:   \t18.209999084472656%\n",
            "in:   \t13.34000015258789%\n",
            "whisk:   \t6.559999942779541%\n",
            "bring:   \t6.53000020980835%\n",
            "combine:   \t6.099999904632568%\n",
            "--------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "info = text_generator.generate(\n",
        "    \"recipe for chocolate ice cream |\", max_tokens=7, temperature=1.0\n",
        ")\n",
        "print_probs(info, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "011cd0e0-956c-4a63-8ec3-f7dfed31764e",
      "metadata": {
        "id": "011cd0e0-956c-4a63-8ec3-f7dfed31764e",
        "outputId": "c525eaca-0e54-48ce-9423-1d4fab0e4bf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "recipe for chocolate ice cream | preheat\n",
            "\n",
            "\n",
            "PROMPT: recipe for chocolate ice cream |\n",
            "preheat:   \t81.33999633789062%\n",
            "in:   \t17.18000030517578%\n",
            "whisk:   \t0.49000000953674316%\n",
            "bring:   \t0.47999998927116394%\n",
            "combine:   \t0.3400000035762787%\n",
            "--------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "info = text_generator.generate(\n",
        "    \"recipe for chocolate ice cream |\", max_tokens=7, temperature=0.2\n",
        ")\n",
        "print_probs(info, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temps = [0.5, 1.3]"
      ],
      "metadata": {
        "id": "lAgkcqoM4S9G"
      },
      "id": "lAgkcqoM4S9G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_prompt = \"recipe for roasted vegetables |\"\n",
        "\n",
        "for t in temps:\n",
        "    print(f\"Temperature = {t}\")\n",
        "\n",
        "    _ = text_generator.generate(\n",
        "            new_prompt,\n",
        "            max_tokens=50,\n",
        "            temperature=t\n",
        "        )"
      ],
      "metadata": {
        "id": "-RNvBLGk4xfS",
        "outputId": "bb08bce8-ceb6-4898-cba7-e24ccefbaeb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-RNvBLGk4xfS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature = 0.5\n",
            "\n",
            "generated text:\n",
            "recipe for roasted vegetables | preheat oven to 400°f . butter a 9 - by 9 - inch baking pan . in a small bowl stir together yolks , and salt to taste , then add 1 / 2 cup water and stir to coat . sprinkle with salt and\n",
            "\n",
            "Temperature = 1.3\n",
            "\n",
            "generated text:\n",
            "recipe for roasted vegetables | sauté up fillets with one / 4 - 3 bundt pan , about 1 / 2 inch pick sides of plunger with artichokes , 3–4 . ) 2 tablespoons oil . combine first 7 ingredients in processor and dutch barbecue ( be diameter would deep\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9jY5utKt471E"
      },
      "id": "9jY5utKt471E",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}