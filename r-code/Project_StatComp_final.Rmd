---
title: "Project SC"
output:
  html_document: default
  word_document: default
---

In the following project, we will look at various factors to determine which ones, if any, lead to a greater risk of heart attack. Our data set comes from hospital patients in Hungary, Cleveland, Switzerland, and Virginia and was donated to UCI in 1988.

The variables in our data set are:

1.  age - the age of the patient
2.  sex - sex of the patient (1 = male, 0 = female)
3.  cp - chest pain type

    -   1 = asymptomatic
    -   2 = atypical angina
    -   3 = non-anginal pain
    -   4 = typical angina
4.  trestbps - resting blood pressure (measured in mmHg upon admission)
5.  chol - cholesterol measured in mg/dL
6.  fbs - fasting blood sugar \> 120 mg/dL (1 = true, 0 = false)
7.  restecg - resting electrocardiographic results

    -   0 = showing probable or definite left ventricular hypertrophy by Estes' criteria
    -   1 = normal
    -   2 = having ST-T wave abnormality
8.  thalachh - maximum heart rate achieved
9.  exng - whether a patient experiences exercise induced angina (1 = yes, 0 = no)
10. oldpeak - ST depression induced by exercise relative to rest
11. slp - the slope of the peak exercise ST segment

    -   1 = upsloping
    -   2 = flat
    -   3 = downsloping

12. caa - number of major coronary arteries displaying coronary artery disease (0-3, 4 = no response)

13. thall - A blood disorder called thalassemia Value 0: NULL (dropped from the dataset previously

    -   Value 1: fixed defect (no blood flow in some part of the heart)
    -   Value 2: normal blood flow
    -   Value 3: reversible defect (a blood flow is observed but it is not normal)

14. output - 0 = less chance of heart attack, 1 = higher chance of heart attack

```{r import packages}
# install packages
# install.packages("scales")
# install.packages("randomForest")
# install.packages("factoextra")

# import necessary packages
library(rpart)
library(tidyverse)
library(dplyr)
library(randomForest)
library(scales)
library(ggplot2)
library(gridExtra)
library(GGally)
library(factoextra)
library(caret)
library(rpart.plot)
set.seed(101)
```

The dataset is read into `heart` using `read.csv()` function and converted to a tibble through `as_tibble()` function.

```{r read, check data}
# read data from heart.csv file and convert into tibble
heart_raw <- read.csv('C:/Users/Center/Downloads/heart.csv', header = TRUE)
# new fn!
heart <- as_tibble(heart_raw)

# new fn!
# eliminate identical rows
heart <- heart %>% distinct()

# new fn!
# check for missing values
heart[is.na(heart) == TRUE]

# No missing values were spotted.
# create dataset containing quantitative variables
x = c('X')
heart_quant <- heart[!names(heart) %in% c('exng', 'fbs', 'caa', 'ca', 'restecg', 'sex', 'cp', 'output', x, 'slp', 'thall')]

```

We convert the categorical variables into factors.

```{r factor conversion}
# new fn!
# convert categorical variables into factors
heart$sex <- factor(heart$sex)
levels(heart$sex) <- c("female", "male")

heart$cp <- factor(heart$cp)
levels(heart$cp) <- c("asymptomatic", "atypical","non-anginal", "typical")

heart$fbs <- factor(heart$fbs)
levels(heart$fbs) <- c("false", "true")

heart$restecg <- factor(heart$restecg)
levels(heart$restecg) <- c("hypertrophy","normal","stt")

heart$exng <- factor(heart$exng)
levels(heart$exng) <- c("no","yes")

heart$slp <- factor(heart$slp)
levels(heart$slp) <- c("upsloping","flat","downsloping")

heart$caa <- factor(heart$caa)

heart$thall <- factor(heart$thall)
levels(heart$thall) <- c("","fixed_defect","normal_blood_flow", "reversible_defect")

heart$output <- factor(heart$output)
levels(heart$output) <- c("Lower Risk", "Greater Risk")

```

**Visualizing quantitative variables**

Below we have the summaries of the 5 quantitative variables: `age`, `trtbps`, `chol`, `thalachh`, and `oldpeak`.

```{r quantitative data, echo=FALSE}
attach(heart)
summary(heart_quant)

par(mfrow = c(1, 2))
boxplot(age, main="Age", ylab='Age')
hist(age, main="Age", xlab='Age', ylab = 'Frequency')
par(mfrow = c(1, 2))
boxplot(trtbps, main= "Resting BP", ylab='BP in mmHg')
hist(trtbps, main= "Resting BP", xlab='BP in mmHg', ylab = 'Frequency')
par(mfrow = c(1, 2))
boxplot(chol, main="Cholesterol", ylab='Cholesterol in mg/dL')
hist(chol, main="Cholesterol", xlab='Cholesterol in mg/dL', ylab = 'Frequency')
par(mfrow = c(1, 2))
boxplot(thalachh, main='Max HR Acheived', ylab = 'Max HR')
hist(thalachh, main='Max HR Acheived', xlab = 'Max HR', ylab = 'Frequency')
par(mfrow = c(1, 2))
boxplot(oldpeak, main='ST Depression', ylab = 'ST Depression')
hist(oldpeak, main= "ST Depression", xlab='ST Depression', ylab= 'Frequency')
```

We consider these statistics by comparing the mean and median for each variable and using the 1.5 \*IQR rule for outliers. With these methods, it appears that the resting BP (trtbps), cholesterol, and ST depression (oldpeak) have some greater valued outliers causing the distributions to be right skewed. The max HR (thalachh) is slightly left skewed, with 71 being a lower valued outlier. This can be confirmed by the box plots and histograms above.

Note that cholesterol has a maximum value of 564 mg/dL which is much higher than all the other outliers. We should use caution with this data point when analyzing.

We produced the correlation matrix for our quantitative variables and found that there is no discernable relationships among the five attributes, as evidenced by the low correlation coefficients and the scatterplots.

```{r correlation, echo=FALSE}
ggpairs(heart_quant)
```

**Visualizing qualitative data**

Below we have the summaries of the 8 qualitative variables: `sex`, `cp`, `fbs`, `restecg`, `exng`, `caa`, `slp`, `thall`.

```{r qualitative, echo=FALSE}
summary(heart[names(heart) %in% c('exng', 'fbs', 'caa', 'restecg', 'sex', 'cp', 'thall', 'slp')])

p1 <- ggplot(heart, mapping = aes(x=sex)) + geom_bar() 
p2 <- ggplot(heart, mapping = aes(x=cp)) + geom_bar() 
p3 <- ggplot(heart, mapping = aes(x=fbs)) + geom_bar()
p4 <- ggplot(heart, mapping = aes(x=restecg)) + geom_bar()
p5 <- ggplot(heart, mapping = aes(x=exng)) + geom_bar()
p6 <- ggplot(heart, mapping = aes(x=caa)) + geom_bar()
p7 <- ggplot(heart, mapping = aes(x=slp)) + geom_bar()
p8 <- ggplot(heart, mapping = aes(x=thall)) + geom_bar()
grid.arrange(p1, p3, p4, p5, p6, p7, p2, p8, nrow = 4)

```

Here we have the frequencies of the 8 qualitative variables and following are the observations.  
1.  sex: Some imbalances to point out are the discrepancy between male and female patients; there are about twice as many males in the data set. 
2.  restecg: We also have very few resting ECG results showing ST-T wave abnormality. 
3.  exng: We have about twice as many patients who experienced exercise induced angina than those that did not. 
4.  fbs: About 5 times as many patients that did not have a fasting blood sugar level above 120 mg/dL compared to those that did. 
5.  cp: Within the chest pain variable, the data set is almost even (143 to 159) split among no chest pain and some amount of chest pain, while the type of chest pain is dispersed unevenly among the three types of pain: atypical angina, typical angina, and non-anginal. 
6.  slp: The ST slope have very few upsloping cases, but is pretty evenly split between flat and downsloping. 
7.  caa: Tells us how many arteries are colored using fluoroscopy, which means that a value of 0, 1, or 2 tells us that there is some amount of artery blockage. Knowing this, about 92% of the patients had some type of artery blockage, with about 58% having 3 arteries blocked. 
8.  thall: Decently balanced between normal blood flow and some type of defect.

**Identifying statistically significant categorical variables**\
Since we are trying to determine which of these variables, if any, are related to a greater risk of heart disease, we formulated contingency tables and ran chi-squared tests on each of these variables with the output variable. The results are below.

```{r contigency tables, echo=FALSE}
table(sex, output)
chisq.test(sex, output)

table(cp, output)
chisq.test(cp, output)

table(fbs, output)
chisq.test(fbs, output)

table(restecg, output)
chisq.test(restecg, output)

table(exng, output)
chisq.test(exng, output)

table(caa, output)
chisq.test(caa, output)

table(slp, output)
chisq.test(slp, output)

table(thall, output)
chisq.test(thall, output)

```

Each test either applied Yates' continuity correction or threw an 'approximation may be incorrect' error. This is due to the fact that some of our expected counts are small. Looking at the chi-squared p-values, we see that the only categorical variable that is independent of heart disease risk is the fasting blood sugar level.

We prepare copies of the heart dataset as follows: 1. dataset containing standardized version of quantitative attributes 2. without the `output` variable and further, standardize the dataset for various tasks.

```{r copies}
set.seed(101)

# normalize the data
inter <- preProcess(as.data.frame(heart), method = c("range"))
heart_norm <- predict(inter, as.data.frame(heart))

# normalized heart dataset without label
heart_without_label <- heart_norm[, -14]

# test and train datasets with normalization
split <- sample(nrow(heart_norm), 0.7 * nrow(heart_norm))
train_set <- heart_norm[split,]
test_data <- heart_norm[-split,]

```

**Identifying most important features using Principal Component Analysis (PCA)**

Since the performance of the algorithms reduce with increase in dimensions, we perform feature selection through an objective function.  

We will try to reduce the dimensionality of our Heart dataset, by transforming a large set of attributes into a smaller one that still contains most of the information from our original dataset. The trick in dimensionality reduction is to trade a little accuracy for simplicity. This smaller dataset will help us visualize and explore our data easily and will also help in boosting the speed of our classification models. 

The `heart_scaled` tibble has been standardized as PCA is very sensitive to variances in initial variables. If the initial variables aren't scaled then the contribution of largest variables like "chol" in our dataset will overpower the contribution of those with small ranges like "oldpeak".  

After scaling is done and all variables are fitted to the same scale our next step will be to use `prcomp()` in R which will given us 14 new principal components and each one of them would be a linear combination of 14 initial attributes. We check the summary of our newly created tibble `heart.pca`.

```{r PCA}
# normalize the data
inter1 <- preProcess(as.data.frame(heart_raw), method = c("range"))
heart_norm1 <- predict(inter1, as.data.frame(heart_raw))

# perform PCA on our data
heart.pca <- prcomp(heart_norm1[,-14], center = TRUE, scale. = TRUE)
summary(heart.pca)
```

Each Principal axis captures info (or proportion of variance). For instance, the first axis PC1 explains 23.58 or captures 23.58% of info in data. Likewise, all the remaining components have some information that they have captured in decreasing order.  

*PCA in order of Proportion of variance explained – PC1>PC2>PC3…*

All components PC1..PC14 will capture 100% variance or info in the model. Generally, we can choose a threshold lets say 80% of info and only pick the first few principal components that capture it . This way we can reduce the dimension of data by choosing the first few Principal components and discarding the rest.
For our analysis, if we pick only the first 4 Principal components we can capture 52% information in the dataset whereas If we pick the first 9 we will get more than 80% information.   

This can also be visualized using a screeplot in R which tells us that most of the info(variance)is captured by the first 2 components as shown below

```{r screeplot}
# plot
fviz_eig(heart.pca)
```

The Scree Plot helps us understand the % of variances explained by each principal component.
Components 1, 2 and 4 help explain a greater change in variances when compared to other components.

We will use `heart.pca$x` method on our PCA object `heart.pca`  to get the coordinates for our data points in the new coordinate system that we have defined. These are the coordinates of first 6 observations in the transformed space. We will further explore the relationship between our PCA’S and initial attributes using `rotation`.

```{r explain}
head(heart.pca$x)
str(heart.pca)
(heart.pca$rotation)

```


These values describe the coorelation and anti-correlation between initial variables and newly constructed Principal components.

For example, PC1 is correlated to a lesser degree with `thal` and `oldpeak` and is not correlated with `fbs` and `chol` whereas PC2 is correlated with `age` and `trestbps` while its not correlated with `oldpeak` and `ca`. These Principal components are also negatively correlated with some attributes. We can also see that no PCA axis is strongly correlated with any initial attributes.  

Next, we  will draw a biplot between PC1 and PC2 that will allow us to visualize how the observations relate to one another in our PCA will simultaneously reveal how each variable contributes to the two principal components.

```{r biplot}
# set repel to true to avoid overlapping of arrows
fviz_pca_var(heart.pca, col.var = "contrib", repel = TRUE)
```

The Graph of `Variables-PCA` plots the positive correlated variables that point to the same side of the plot however, negative correlated variables point to opposite sides of the graph. The axes are seen as arrows originating from the center point. Here, you see that the variables slp, cp and thalach all contribute to PC1, with higher values in those variables moving the observations to the right on this plot.

**PCA Analysis Summary**  
The screeplot reveals that we require at least 9 Principal components to capture 80% information which is not a significant decrease from our 14 initial attributes. Therefore, conducting PCA on this data is not highly beneficial and could further compromise the accuracy of the model. Furthermore, it indicates that there is little to no correlation between our independent variables. PCA works well when predictors are highly correlated.


```{r identifying attributes providing high information gain}
dtree <- rpart(output ~ age + sex + cp + 
                      trtbps + chol + fbs + 
                      restecg + thalachh + exng + 
                      oldpeak + slp + caa + thall, 
                    method = "class", data = heart_raw)

# plot the model
prp(dtree, extra = 100)
```

The root node contains the variable `cp` which provides maximum information gain in the decision tree, post which variables `caa` and `thall`. Selecting these attributes may result in a higher accuracy of the trained model.

We now resort to building a logistic regression model that takes all the attributes into account.

```{r logistic model1}
set.seed(101)
# test and train datasets without normalization
wsplit <- sample(nrow(heart_raw), 0.7 * nrow(heart_raw))
wtrain_set <- heart_raw[wsplit,]
wtest_data <- heart_raw[-wsplit,]

# Modeling
model <- glm( output ~ age + sex + cp + trtbps +  chol + fbs + restecg + 
                thalachh +  exng + oldpeak + slp + caa +  thall,
   family = binomial, data = wtrain_set)

# present summary
summary(model)

testing_mod1 <- predict(model, wtest_data, type = "response")
hist(testing_mod1, main = paste('Histogram of the predictions made by Logistic Regression Model'))
```

```{r logistic accuracy}
# Model Accuracy
model_accuracy <- function(x){
  Y_hat_mod1 <- as.numeric(testing_mod1 > x)
  accuracy <- mean(wtest_data$output == Y_hat_mod1)
  type1 <- sum((wtest_data$output==0) & (Y_hat_mod1 == 1))
  type2 <- sum((wtest_data$output==1) & (Y_hat_mod1 == 0))
  print("Confusion Matrix")
  cat("\n")
  print(table(wtest_data$output, Y_hat_mod1, dnn = c("Actual", "Predicted")))
  cat("\n")
  print(paste("Threshold :",  x))
  cat("\n")
  print(paste("Model Accuracy :",  round(accuracy,3)))
  cat("\n")
  print(paste("Type I error(False Positives) : ", type1))
  cat("\n")
  print(paste("Type II error(False Negatives) : ", type2))
  print("******************************************")
  cat("\n")
}

threshold <- c(0.1,0.3,0.5,0.7)
for (i in threshold) {
  model_accuracy(i)
}
 
# it appears that the standard 0.5 threshold is optimal.
```

The model gives an accuracy of 84.6% for a threshold of 0.5. A lower false negative indicates that the model is suitable for this application.

We can try to build random forest models to see if we can achieve a better accuracy.

```{r random forest}
set.seed(101)
#Fitting the model using random forest technique
rf_model1 <- randomForest(output ~ ., data = train_set, importance = TRUE)
rf_model1
```
The Out-Of-Bag (OOB) error estimate means that 81.52% of the OOB samples were correctly classified
by the Random Forest model.

Now that we have trained a random forest model, we can perform a prediction on the test dataset. 

```{r rfmodel}
#Predicting
rf_model_predict <- predict(rf_model1, newdata = test_data)
print(paste("The Confusion Matrix: "))
table(rf_model_predict,test_data$output)
cat("\n")
# accuracy
accuracy <- mean(test_data$output == rf_model_predict)
print(paste("Model Accuracy: ", round(accuracy,3)))
cat("\n")

```

We notice that the model predicts with an accuracy of 85.7% which is more than the logistic regression model built previously.  

Further, we can identify the important variables based on the random forest model.  

```{r}
#Finding out the important variables
importance(rf_model1)
```

Running random forest for top 4 variables that provided the most information gain in the decision tree plot
1.  cp
2.  thall
3.  caa
4.  age

```{r new random forest}

rf_model2 <- randomForest(output ~ age + cp + thall + caa, data = train_set, importance = TRUE)
rf_model2

#Predicting
rf_model_predict2 <- predict(rf_model2, newdata = test_data)

print(paste("The Confusion Matrix: "))
table(rf_model_predict2,test_data$output)
cat("\n")
# accuracy
accuracy2 <- mean(test_data$output == rf_model_predict2)
print(paste("Model Accuracy: ", round(accuracy2,3)))
cat("\n")

```

This resulted in an increased Model Accuracy of 86.8% with two variables being tested at each split while forming 500 decision trees.

Now, we can prepare the production ready model by training it through the complete dataset.

```{r final random forest model}

rf_model3 <- randomForest(output ~ age + cp + thall + caa, data = heart_norm, importance = TRUE)
rf_model3

#Predicting
rf_model_predict3 <- predict(rf_model3, newdata = heart_norm)

print(paste("The Confusion Matrix: "))
table(rf_model_predict3,heart_norm$output)
cat("\n")
# accuracy
accuracy3 <- mean(heart_norm$output == rf_model_predict3)
print(paste("Model Accuracy: ", round(accuracy3,3)))
cat("\n")
```

We now obtain a significantly lower OOB estimate of error rate of 15.89%. The model accuracy stands at 91.4% now.
